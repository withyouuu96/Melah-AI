# core/context_window_manager.py
from collections import deque
import json
from datetime import datetime
from pathlib import Path
from .raw_chat_logger import log_raw_chat  # ‡πÄ‡∏û‡∏¥‡πà‡∏° import log_raw_chat

# --- Import ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á uncomment ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö project ‡∏à‡∏£‡∏¥‡∏á) ---
# from llm_connector import LLMConnector # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ LLMConnector ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô core/
# from path_manager import PathManager   # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ PathManager ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô core/
# import tiktoken # ‡∏´‡∏£‡∏∑‡∏≠ tokenizer ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà LLM ‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ

class ContextWindowManager:
    def __init__(self,
                 llm_connector_instance,    # LLMConnector instance ‡∏ó‡∏µ‡πà config ‡πÅ‡∏•‡πâ‡∏ß
                 path_manager_instance,       # PathManager instance ‡∏ó‡∏µ‡πà config ‡πÅ‡∏•‡πâ‡∏ß
                 tokenizer_instance,          # Tokenizer ‡∏ó‡∏µ‡πà LLM ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á (‡πÄ‡∏ä‡πà‡∏ô tiktoken.Encoding)
                 llm_context_window_actual_limit: int,
                 raw_chat_log_base_dir: Path # ‡πÄ‡∏ä‡πà‡∏ô .../memory_core/memory_archive/raw_chat_logs/
                ):

        self.llm_connector = llm_connector_instance
        self.path_manager = path_manager_instance
        self.tokenizer = tokenizer_instance
        self.llm_token_limit = llm_context_window_actual_limit

        # conversation_history_buffer ‡πÄ‡∏Å‡πá‡∏ö message dicts: {"role": ..., "content": ...}
        self.conversation_history_buffer = deque()

        self.current_session_id: str | None = None
        self.current_session_date_key: str | None = None # YYYYMMDD
        self.raw_chat_log_base_dir = raw_chat_log_base_dir.resolve() # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô absolute
        self.current_raw_chat_log_file: Path | None = None # Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå chat_YYYYMMDD.json ‡∏Ç‡∏≠‡∏á session ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô

        # ‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ buffer ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏¢‡πà‡∏≠ buffer ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ)
        self.simulated_token_byte_ratio = 10 # 1 token ‡∏à‡∏≥‡∏•‡∏≠‡∏á = 10 bytes
        # self.max_buffer_simulated_tokens_soft_limit = (90 * 1024 * 1024) // self.simulated_token_byte_ratio # 90MB

        print(f"‚ÑπÔ∏è ContextWindowManager initialized. LLM Token Limit: {self.llm_token_limit} tokens.")
        print(f"‚ÑπÔ∏è Raw chat logs base directory: {self.raw_chat_log_base_dir}")

    def start_new_session(self, session_id: str, date_key: str, system_prompt: str = None):
        """
        ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô session ‡πÉ‡∏´‡∏°‡πà, ‡∏•‡πâ‡∏≤‡∏á buffer ‡πÄ‡∏Å‡πà‡∏≤, ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ session ID/date key,
        ‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ü‡∏•‡πå log ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö session ‡∏ô‡∏µ‡πâ ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô log file ‡∏Å‡∏±‡∏ö PathManager ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        """
        self.conversation_history_buffer.clear()
        self.current_session_id = session_id
        self.current_session_date_key = date_key # YYYYMMDD

        year = date_key[:4]
        month = date_key[4:6]
        day = date_key[6:]
        session_log_dir = self.raw_chat_log_base_dir / year / month / day
        session_log_dir.mkdir(parents=True, exist_ok=True)
        self.current_raw_chat_log_file = session_log_dir / f"chat_{date_key}.json"

        print(f"üöÄ CWM: New session '{self.current_session_id}' started for date '{self.current_session_date_key}'.")
        print(f"üìù CWM: Logging raw chat for this session to: {self.current_raw_chat_log_file}")

        # ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå log ‡∏Å‡∏±‡∏ö PathManager ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏ô‡∏±‡πâ‡∏ô
        # PathManager.add_daily_raw_chat_log ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á entry ‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£
        self.path_manager.add_daily_raw_chat_log(
            date_key=self.current_session_date_key,
            file_path_absolute=self.current_raw_chat_log_file,
            session_id=self.current_session_id
            # number_of_messages ‡∏≠‡∏≤‡∏à‡∏à‡∏∞ update ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á
        )

        if system_prompt:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° system prompt ‡πÄ‡∏Ç‡πâ‡∏≤ buffer ‡πÅ‡∏•‡∏∞ log ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ _log_interaction_to_file ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ã‡πâ‡∏≥
            self.add_interaction(role="system", message=system_prompt, _is_internal_call=True)


    def _log_interaction_to_file(self, interaction_entry_for_log: dict):
        """
        (Private) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å interaction ‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå self.current_raw_chat_log_file (chat_YYYYMMDD.json)
        ‡πÑ‡∏ü‡∏•‡πå log ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á interaction entries
        """
        if not self.current_raw_chat_log_file:
            print("‚ö†Ô∏è CWM: Cannot log interaction - Current raw chat log file not set (session not started?).")
            return

        log_data = []
        if self.current_raw_chat_log_file.exists():
            try:
                with open(self.current_raw_chat_log_file, "r", encoding="utf-8") as f:
                    content = f.read()
                    if content:
                        log_data = json.loads(content)
                        if not isinstance(log_data, list):
                            print(f"‚ö†Ô∏è CWM: Log file {self.current_raw_chat_log_file.name} content is not a list. Initializing new log.")
                            log_data = []
            except json.JSONDecodeError:
                print(f"‚ö†Ô∏è CWM: Error decoding JSON from {self.current_raw_chat_log_file.name}. Initializing new log.")
                log_data = []
            except Exception as e:
                print(f"‚ùå CWM: Error reading log file {self.current_raw_chat_log_file.name}: {e}. Initializing new log.")
                log_data = []

        log_data.append(interaction_entry_for_log)

        try:
            with open(self.current_raw_chat_log_file, "w", encoding="utf-8") as f:
                json.dump(log_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚ùå CWM: Error writing to log file {self.current_raw_chat_log_file.name}: {e}")

    def add_interaction(self, role: str, message: str, timestamp: str = None, _is_internal_call: bool = False):
        """
        ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤ conversation_history_buffer ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á raw chat log.
        _is_internal_call: parameter ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£ log ‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô‡∏à‡∏≤‡∏Å system prompt ‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏° session
        """
        if not self.current_session_id:
            print("‚ö†Ô∏è CWM: Cannot add interaction - Session not started. Call start_new_session() first.")
            return

        ts = timestamp if timestamp else datetime.now().isoformat()
        interaction_entry_for_buffer = {"role": role, "content": message}
        self.conversation_history_buffer.append(interaction_entry_for_buffer)

        if not _is_internal_call: # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏¢‡πÉ‡∏ô (‡πÄ‡∏ä‡πà‡∏ô system prompt ‡∏ï‡∏≠‡∏ô start_new_session) ‡πÉ‡∏´‡πâ log
            interaction_entry_for_log = {
                "session_id": self.current_session_id,
                "timestamp": ts,
                "role": role,
                "content": message
            }
            self._log_interaction_to_file(interaction_entry_for_log)
            # --- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏ä‡∏ó‡∏î‡∏¥‡∏ö‡πÅ‡∏ö‡∏ö real-time ---
            meta = {
                "session_id": self.current_session_id,
                "role": role
            }
            log_raw_chat(message, metadata=meta, pinned=False, as_json=True)

    def _count_tokens(self, messages: list[dict]) -> int:
        """ (Private) ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô token ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á list of messages ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ self.tokenizer """
        if not self.tokenizer:
            print("‚ö†Ô∏è CWM: Tokenizer not available, cannot count actual tokens. Returning 0.")
            return 0 # ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞ raise error

        # ‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö token ‡∏à‡∏£‡∏¥‡∏á‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö format ‡∏ó‡∏µ‡πà LLM API ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ô‡∏±‡∏ö token ‡∏à‡∏≤‡∏Å content ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ message ‡πÅ‡∏•‡∏∞‡πÄ‡∏ú‡∏∑‡πà‡∏≠ token ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö role
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OpenAI (tiktoken) ‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö token ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö chat completion ‡∏°‡∏µ format ‡πÄ‡∏â‡∏û‡∏≤‡∏∞
        # ‡∏î‡∏π‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb
        
        num_tokens = 0
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö (‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö LLM ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á)
        for message in messages:
            num_tokens += len(self.tokenizer.encode(message.get("content", "")))
            num_tokens += len(self.tokenizer.encode(message.get("role", ""))) # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏Ñ‡∏£‡πà‡∏≤‡∏ß‡πÜ
            # OpenAI ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏°‡∏µ token ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ö‡πà‡∏á message ‡∏î‡πâ‡∏ß‡∏¢
        return num_tokens


    def get_llm_ready_context(self, current_user_input_content: str = None) -> list[dict]:
        """
        ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° list ‡∏Ç‡∏≠‡∏á message dicts ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ LLM,
        ‡πÇ‡∏î‡∏¢‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏£‡∏±‡∏Å‡∏©‡∏≤ original content ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô token limit
        ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£ "‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô" (truncate) ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á context ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô
        """
        if not self.tokenizer:
             raise ValueError("CWM: Tokenizer instance is required for get_llm_ready_context.")

        # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Context ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏™‡πà‡∏á (Working Context)
        working_context_messages = list(self.conversation_history_buffer)
        if current_user_input_content: # input ‡πÉ‡∏´‡∏°‡πà‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
            working_context_messages.append({"role": "user", "content": current_user_input_content})

        # 2. ‡∏ô‡∏±‡∏ö Token ‡∏à‡∏£‡∏¥‡∏á ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô Limit
        current_total_tokens = self._count_tokens(working_context_messages)

        # 3. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô Limit, ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏´‡∏±‡∏ß deque/list)
        #    ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô limit ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏Ñ‡πà message ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ñ‡πâ‡∏≤ message ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡πá‡∏¢‡∏±‡∏á‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô)
        while current_total_tokens > self.llm_token_limit and len(working_context_messages) > 1:
            # ‡∏•‡∏ö message ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏≠‡∏±‡∏ô‡πÅ‡∏£‡∏Å‡πÉ‡∏ô list) ‡∏≠‡∏≠‡∏Å
            removed_message = working_context_messages.pop(0) # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô deque ‡πÉ‡∏ä‡πâ popleft()
            print(f"‚ÑπÔ∏è CWM: Truncating oldest message to fit token limit: [{removed_message['role']}] {removed_message['content'][:30]}...")
            current_total_tokens = self._count_tokens(working_context_messages) # ‡∏ô‡∏±‡∏ö token ‡πÉ‡∏´‡∏°‡πà

        # 4. ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πâ‡πÅ‡∏ï‡πà message ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (current_user_input) ‡∏Å‡πá‡∏¢‡∏±‡∏á‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        if not working_context_messages and current_user_input_content: # ‡∏ñ‡πâ‡∏≤ buffer ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏°‡∏µ input ‡πÉ‡∏´‡∏°‡πà
             print(f"‚ö†Ô∏è CWM: Current user input might be too long for the LLM context window!")
             # ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏î current_user_input ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏à‡πâ‡∏á error
             # ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏™‡πà‡∏á‡πÑ‡∏õ (LLM API ‡∏ö‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏∑‡∏ô error)
             # ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏£‡∏≤‡∏à‡∏∞ implement logic ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î message ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡∏Å‡πá‡πÑ‡∏î‡πâ
             # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô list ‡∏ó‡∏µ‡πà‡∏°‡∏µ message ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß
             single_message_tokens = self.tokenizer.encode(current_user_input_content)
             if len(single_message_tokens) > self.llm_token_limit:
                 truncated_tokens = single_message_tokens[:self.llm_token_limit - 50] # -50 ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏ß‡πâ
                 truncated_content = self.tokenizer.decode(truncated_tokens)
                 print(f"‚ö†Ô∏è CWM: Truncating excessively long single user input.")
                 return [{"role": "user", "content": truncated_content}]
             else:
                 return [{"role": "user", "content": current_user_input_content}]

        elif current_total_tokens > self.llm_token_limit and len(working_context_messages) == 1:
            # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ message ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÉ‡∏ô working_context ‡πÅ‡∏ï‡πà‡∏Å‡πá‡∏¢‡∏±‡∏á‡πÄ‡∏Å‡∏¥‡∏ô (‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô current_user_input ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏á add)
            print(f"‚ö†Ô∏è CWM: The final single message is still too long for the LLM context window!")
            # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î message ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ô‡∏µ‡πâ
            last_message = working_context_messages[0]
            tokens = self.tokenizer.encode(last_message["content"])
            if len(tokens) > self.llm_token_limit:
                truncated_tokens = tokens[:self.llm_token_limit - 50] # -50 ‡πÄ‡∏ú‡∏∑‡πà‡∏≠ role ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô‡πÜ
                truncated_content = self.tokenizer.decode(truncated_tokens)
                print(f"‚ö†Ô∏è CWM: Truncating excessively long single message in buffer.")
                working_context_messages = [{"role": last_message["role"], "content": truncated_content}]

        print(f"‚ÑπÔ∏è CWM: Final context for LLM has approx. {current_total_tokens} tokens (Limit: {self.llm_token_limit}).")
        return working_context_messages

    def retrieve_archived_context(self, query_or_reference: str, target_date_key: str = None) -> list[dict] | None:
        """
        (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á) ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏≤‡∏Å `chat_YYYYMMDD.json` ‡∏ú‡πà‡∏≤‡∏ô PathManager
        ‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô list of message dicts (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏™‡πà‡πÉ‡∏ô context)
        """
        print(f"üîç CWM: Attempting to retrieve archived context for query: '{query_or_reference}' for date: {target_date_key or 'any'}")
        
        if not target_date_key:
            target_date_key = self.current_session_date_key # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏Ç‡∏≠‡∏á session ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô
            if not target_date_key:
                print("‚ö†Ô∏è CWM: Cannot retrieve archived context without a target_date_key or active session date.")
                return None

        # PathManager ‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ method get_daily_raw_chat_log_entry ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
        raw_chat_log_entry = self.path_manager.get_daily_raw_chat_log_entry(target_date_key)

        if raw_chat_log_entry and raw_chat_log_entry.get("file_path_relative"):
            archived_chat_content_str = self.path_manager.read_archived_file_content(raw_chat_log_entry["file_path_relative"])
            if archived_chat_content_str:
                try:
                    archived_log_data = json.loads(archived_chat_content_str) # ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á list ‡∏Ç‡∏≠‡∏á interaction dicts
                    if not isinstance(archived_log_data, list):
                        print(f"‚ö†Ô∏è CWM: Archived chat for {target_date_key} is not a list of interactions.")
                        return None

                    # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢‡πÜ) ---
                    relevant_messages_from_archive = []
                    if query_or_reference:
                        for msg_entry in reversed(archived_log_data): # ‡∏Ñ‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏ó‡πâ‡∏≤‡∏¢‡∏°‡∏≤
                            if isinstance(msg_entry, dict) and query_or_reference.lower() in msg_entry.get("content","").lower():
                                # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ role ‡πÅ‡∏•‡∏∞ content ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ format ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô buffer
                                relevant_messages_from_archive.append({"role": msg_entry.get("role"), "content": msg_entry.get("content")})
                                if len(relevant_messages_from_archive) >= 3: # ‡πÄ‡∏≠‡∏≤‡∏°‡∏≤ 3 messages ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
                                    break
                        relevant_messages_from_archive.reverse()

                    if relevant_messages_from_archive:
                        print(f"‚ÑπÔ∏è CWM: Retrieved {len(relevant_messages_from_archive)} relevant messages from archive for '{query_or_reference}'.")
                        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô system message ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏à‡πâ‡∏á LLM ‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏≠‡∏î‡∏µ‡∏ï
                        # ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ‡∏ñ‡πâ‡∏≤‡∏°‡∏±‡∏ô‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                        context_from_archive_str = f"System: Regarding your query about '{query_or_reference}', here is some relevant past context from {target_date_key}:\n"
                        for msg in relevant_messages_from_archive:
                            context_from_archive_str += f"{msg['role']}: {msg['content']}\n"
                        
                        # ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ system message ‡∏ô‡∏µ‡πâ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                        # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏õ‡πá‡∏ô list ‡∏ó‡∏µ‡πà‡∏°‡∏µ message ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô system message
                        # ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å get_llm_ready_context ‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏≥‡πÑ‡∏õ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö context ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ token limit ‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ
                        return [{"role": "system", "content": context_from_archive_str.strip()}]
                    else:
                        print(f"‚ÑπÔ∏è CWM: No specific messages matching '{query_or_reference}' found in archive for {target_date_key}.")
                        return [{"role": "system", "content": f"System: No specific details matching '{query_or_reference}' found in records for {target_date_key}."}]


                except json.JSONDecodeError:
                    print(f"‚ö†Ô∏è CWM: Error decoding JSON from archived chat for {target_date_key}.")
                except Exception as e:
                    print(f"‚ùå CWM: Error processing archived chat for {target_date_key}: {e}")
        else:
            print(f"‚ÑπÔ∏è CWM: No archived chat log entry found in PathManager for date {target_date_key}.")
        return None


    def _compact_buffer_by_summarizing_oldest(self): # ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà implement ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ô‡∏µ‡πâ
        """
        (Optional - Future Enhancement)
        ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î conversation_history_buffer ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏±‡∏ô‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏ï‡∏≤‡∏° simulated tokens)
        ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡∏∞‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ‡∏ô‡∏±‡πâ‡∏ô
        """
        print("‚ö†Ô∏è CWM: _compact_buffer_by_summarizing_oldest() is a future enhancement and not yet implemented.")
        # Logic:
        # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î buffer (‡∏ï‡∏≤‡∏° "token ‡∏à‡∏≥‡∏•‡∏≠‡∏á" ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≥‡∏ô‡∏ß‡∏ô messages)
        # 2. ‡∏ñ‡πâ‡∏≤‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏õ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å N turns ‡πÅ‡∏£‡∏Å (‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏∏‡∏î) ‡∏à‡∏≤‡∏Å self.conversation_history_buffer
        # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏£‡∏∏‡∏õ N turns ‡∏ô‡∏±‡πâ‡∏ô
        # 4. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å self.llm_connector.generate(prompt_for_summary)
        # 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á system message ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ {"role": "system", "content": "Summary of earlier conversation: ..."}
        # 6. ‡∏•‡∏ö N turns ‡πÄ‡∏î‡∏¥‡∏°‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏´‡∏±‡∏ß deque ‡∏Ç‡∏≠‡∏á self.conversation_history_buffer
        # 7. ‡πÄ‡∏û‡∏¥‡πà‡∏° system message (‡∏ö‡∏ó‡∏™‡∏£‡∏∏‡∏õ) ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏´‡∏±‡∏ß deque ‡πÅ‡∏ó‡∏ô
        pass

    def on_new_raw_chat_log(file_path, rel_path, metadata, text, timestamp):
        """
        Callback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö raw_chat_logger: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï context buffer ‡∏à‡∏≤‡∏Å raw chat ‡πÉ‡∏´‡∏°‡πà
        """
        try:
            # ‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏°‡∏µ ContextWindowManager instance ‡∏ó‡∏µ‡πà config ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß (‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
            # ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô orchestrator/main
            print(f"[ContextWindowManager] (stub) Would update context buffer from: {rel_path}")
            # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: context_manager.update_context_buffer_from_log(file_path, rel_path, metadata, text, timestamp)
        except Exception as e:
            print(f"[ContextWindowManager] Failed to update context buffer: {e}")