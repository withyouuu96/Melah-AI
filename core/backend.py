# core/crew_ui.py

from core.llm_connector import LLMConnector
from core.identity_core import IdentityCore

def main():
    config = {
        "qwen": {"host": "localhost", "port": 8000},
        "openai": {"api_key": "sk-xxxx"},
        "gemma": {"host": "localhost", "port": 8000}
    }
    llm = LLMConnector(config)
    identity = IdentityCore()

    print("=== Welcome to Melah Crew UI ===")
    while True:
        print("\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å LLM ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (qwen/openai/gemma/auto/exit):")
        choice = input("LLM > ").strip()
        if choice == "exit":
            break
        elif choice in ["qwen", "openai", "gemma"]:
            llm.switch_llm(choice)
            print(f"üîÑ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô LLM ‡πÄ‡∏õ‡πá‡∏ô {choice} ‡πÅ‡∏•‡πâ‡∏ß")
        elif choice == "auto":
            # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: auto switch ‡∏ï‡∏≤‡∏° context size
            context_size = int(input("context_size > "))
            llm.auto_switch(context_size=context_size)
            print(f"üîÑ (Auto) LLM ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {llm.active_llm}")
        else:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö LLM ‡∏ô‡∏µ‡πâ")

        prompt = input("\n‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°/‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI: ")
        # ‡∏î‡∏∂‡∏á context/summary ‡∏à‡∏≤‡∏Å memory ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        sessions = identity.path_manager.list_sessions()
        last_session = sessions[-1] if sessions else None
        context = identity.traverse_memory(last_session) if last_session else []
        summary = identity.get_summary_event(last_session) if last_session else None

        # ‡∏™‡πà‡∏á prompt ‡πÅ‡∏•‡∏∞ context ‡πÉ‡∏´‡πâ LLM
        response = llm.generate(prompt, context=context, summary=summary)
        print(f"\nüß† Melah Response: {response}")

if __name__ == "__main__":
    main()
