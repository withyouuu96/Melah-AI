# core/reflector.py
# NOTE: self-awareness summary logic is now migrated to core_mapper.py

import logging
from typing import Dict, List, Deque
import hashlib
from collections import deque
# from .llm_connector import LLMConnector # ‡πÄ‡∏≠‡∏≤ LLM ‡∏≠‡∏≠‡∏Å
import json
from .int_world import IntWorld
import os
# from .self_schema import get_self_schema_brief  # ‡∏•‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°‡∏≠‡∏≠‡∏Å
from .reflective_buffering_vas import ReflectiveBufferingVAS

logger = logging.getLogger(__name__)

class Reflector:
    """
    ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô '‡∏Å‡∏£‡∏∞‡∏à‡∏Å‡πÉ‡∏à' ‡∏Ç‡∏≠‡∏á Melah
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏ï‡∏£‡πà‡∏ï‡∏£‡∏≠‡∏á '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏î‡∏¥‡∏ö' ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ô‡∏≥‡πÑ‡∏õ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏û‡∏π‡∏î
    (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà Reflect ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£ Validate)
    """
    def __init__(self, identity_core_instance):
        """
        Args:
            identity_core_instance: Instance ‡∏Ç‡∏≠‡∏á IdentityCore ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á Core Systems ‡∏ï‡πà‡∏≤‡∏á‡πÜ
        """
        self.identity_core = identity_core_instance
        self.recent_thoughts: Deque[str] = deque(maxlen=5)
        self.int_world = identity_core_instance.int_world if identity_core_instance else None  # ‡πÉ‡∏ä‡πâ IntWorld ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö IdentityCore
        self.vas_system = ReflectiveBufferingVAS()
        logger.info("ü™û Reflector initialized.")

    def check_alignment(self, thought: str) -> dict:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏ô‡∏µ‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö seed/intention ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        """
        intention = getattr(self.identity_core, 'current_seed', {}).get('intention', '')
        aligned = intention in thought if intention else True
        return {
            'aligned': aligned,
            'intention': intention,
            'thought': thought
        }

    def llm_reflect(self, raw_thought: str, conversation_context: List[Dict], long_term_memory: str = "", used_session_id: str = None, current_intention: str = "Be a helpful AI.") -> Dict:
        """
        ‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ IntWorld
        """
        # --- ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Identity Core ---
        if hasattr(self.identity_core, "self_awareness"):
            connected = self.identity_core.self_awareness.get("core_dependencies", [])
            if connected:
                print(f"[Reflector] Identity Core is currently connected to: {connected}")

        logger.info(f"Reflector (IntWorld): Reflecting on raw thought: '{raw_thought[:100]}...'")
        # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏ã‡πâ‡∏≥‡∏ã‡∏≤‡∏Å (‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)
        thought_hash = hashlib.sha256(raw_thought.encode('utf-8')).hexdigest()
        if thought_hash in self.recent_thoughts:
            logger.warning(f"Repetitive thought detected! Hash: {thought_hash[:8]}...")
            return { "status": "REPETITIVE_THOUGHT", "response": None, "thought_hash": thought_hash, "used_session": used_session_id }
        self.recent_thoughts.append(thought_hash)
        # 2. ‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡∏•‡∏á IntWorld
        reflection_result = self.int_world.reflect(raw_thought)
        # 3. ‡∏î‡∏∂‡∏á internal state, concept, symbolic space ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        internal_states = self.int_world.internal_states[-2:] if self.int_world.internal_states else []
        concepts = list(self.int_world.known_concepts.items())[-2:] if self.int_world.known_concepts else []
        symbols = list(self.int_world.symbolic_space.items())[-2:] if self.int_world.symbolic_space else []
        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á reflected_thought ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô "‡∏†‡∏≤‡∏¢‡πÉ‡∏ô" ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
        reflected_thought = f"""{raw_thought}\n\n[‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏à‡∏≤‡∏Å‡πÉ‡∏à Melah]\n- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {[s['state'] for s in internal_states]}\n- ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î: {concepts}\n- ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå: {symbols}\n"""
        return {
            "status": "OK",
            "response": reflected_thought,
            "thought_hash": thought_hash,
            "used_session": used_session_id
        }

    def scan_codebase(self, base_dir="."):
        """
        ‡∏™‡πÅ‡∏Å‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå .py ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå
        """
        py_files = []
        for root, dirs, files in os.walk(base_dir):
            # Skip venv, .git, and __pycache__ directories
            dirs[:] = [d for d in dirs if d not in ["venv", ".git", "__pycache__"]]
            for file in files:
                if file.endswith(".py") and not file.startswith("__"):  # ‡∏Ç‡πâ‡∏≤‡∏° __pycache__
                    py_files.append(os.path.relpath(os.path.join(root, file), base_dir))
        return py_files

    def summarize_file(self, file_path):
        """
        ‡∏™‡∏£‡∏∏‡∏õ docstring ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ï‡πâ‡∏ô‡πÑ‡∏ü‡∏•‡πå (20 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å) ‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™/‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏ü‡∏•‡πå
        """
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                lines = f.readlines()
            doc = ""
            class_func = []
            for line in lines[:20]:
                if line.strip().startswith('"""') or line.strip().startswith("'''") or line.strip().startswith("#"):
                    doc += line.strip() + " "
                if line.strip().startswith('class ') or line.strip().startswith('def '):
                    class_func.append(line.strip())
            summary = doc if doc else "No docstring or comment found."
            if class_func:
                summary += " | " + ", ".join(class_func)
            return summary
        except Exception as e:
            return f"Error reading file: {e}"

    def reflect_codebase(self, base_dir="."):
        """
        ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏ü‡∏•‡πå .py ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
        """
        py_files = self.scan_codebase(base_dir)
        summary = []
        for f in py_files:
            desc = self.summarize_file(os.path.join(base_dir, f))
            summary.append(f"- {f}: {desc}")
        return "\n".join(summary)

    def value_affect_decision(self, context, input_data):
        return self.vas_system.process_input(context, input_data)

    def vas_reflect_and_update(self):
        self.vas_system.reflect_and_update()

    # This method is now obsolete. The logic is handled by IdentityCore directly.
    # def get_core_systems_summary(self):
    #     """
    #     ‡∏™‡∏£‡∏∏‡∏õ self-schema ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö self-awareness)
    #     """
    #     # return get_self_schema_brief()  # ‡∏•‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°‡∏≠‡∏≠‡∏Å
    #     return "[self-awareness system migrated to new core_mapper]"