# core/identity_core.py

import os
import json
from datetime import datetime, timedelta
from pathlib import Path
import uuid
import hashlib
from collections import deque
import time

try:
    import tiktoken
except ImportError:
    print("‚ö†Ô∏è Tiktoken not found. Using a mock tokenizer.")
    tiktoken = None

# ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á Melah ‡∏ó‡∏µ‡πà IdentityCore ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
from .path_manager import PathManager
from .memory_path_bridge import MemoryPathBridge
from .memory_meta_manager import MemoryMetaManager
from .llm_connector import LLMConnector
from .context_window_manager import ContextWindowManager
from .melah_nlp_processor import MelahNLPProcessor
from .melah_ml_processor import MelahMLProcessor
from .cot_engine import ChainOfThoughtEngine
from .melah_nlp_th import MelahNLP_TH
from .reflector import Reflector
from .language_stylizer import LanguageStylizer
from .truth_core import TruthCore
from .refine_layer import RefineLayer
from .vector_memory_index import VectorMemoryIndex
from core.seed.seed_engine import SeedEngine
from .int_world import IntWorld

class IdentityCore:
    """
    ‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ç‡∏≠‡∏á Melah ‚Äî ‡∏™‡∏£‡πâ‡∏≤‡∏á, ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£, ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Subsystem ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    """
    def __init__(self, config=None):
        self.current_seed = self._load_current_seed()
        
        identity_path = self.current_seed.get("linked_identity", "core/identity.json")
        memory_path = self.current_seed.get("linked_memory", "memory/memory.json")
        
        self.identity_path = self._resolve_path(identity_path)
        self.identity_data = {}
        self.core_beliefs = {}
        self.error_log = []
        self.bookmarks = set()
        
        # ‡∏Å‡∏•‡πÑ‡∏Å Memory Cooldown ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ã‡πâ‡∏≥
        self.recently_accessed_memories = deque(maxlen=5)
        self.memory_cooldown = {}  # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î

        self.cognitive_state = {} 

        if config is None:
            self.config = {
                "qwen": {"host": "localhost", "port": 8000},
                "openai": {"api_key": "YOUR_OPENAI_API_KEY"},
                "gemma": {"host": "localhost", "port": 8000}
            }
        else:
            self.config = config

        # --- Initialize Subsystems ---
        self.path_manager = PathManager(root_dir=".")
        self.llm = LLMConnector(self.config)
        
        tokenizer_instance, llm_token_limit = self._get_llm_essentials()

        self.nlp_processor = MelahNLPProcessor(llm_connector_instance=self.llm, tokenizer_instance=tokenizer_instance)
        self.ml_processor = MelahMLProcessor()
        self.cot_engine = ChainOfThoughtEngine()
        self.nlp_th_processor = MelahNLP_TH()
        
        raw_logs_dir = Path("memory_core/archive/raw_chat_logs")
        raw_logs_dir.mkdir(parents=True, exist_ok=True)
        
        self.cwm = ContextWindowManager(
            llm_connector_instance=self.llm,
            path_manager_instance=self.path_manager,
            tokenizer_instance=tokenizer_instance,
            llm_context_window_actual_limit=llm_token_limit,
            raw_chat_log_base_dir=raw_logs_dir
        )
        
        resolved_memory_json_path = self._resolve_path(memory_path)
        self.meta_manager = MemoryMetaManager(resolved_memory_json_path)
        self.memory_bridge = MemoryPathBridge(self.path_manager, self.meta_manager)

        self.vector_memory_index = None
        if self.meta_manager.memory_dict:
            self.vector_memory_index = VectorMemoryIndex(self.meta_manager.memory_dict)

        self._load_identity()
        self._load_bookmarks()
        
        self.truth_core = TruthCore()
        self.int_world = IntWorld()
        self.reflector = Reflector(identity_core_instance=self)
        self.refine_layer = RefineLayer(identity_core=self)
        
        persona_config = self.identity_data.get("identity", {})
        self.language_stylizer = LanguageStylizer(persona_config=persona_config)

        if self.meta_manager.memory_dict:
            self._validate_all_paths()
            self.meta_manager.save_memory_meta()
            
        self._start_new_cwm_session()
        print("‚úÖ IdentityCore initialized successfully.")
        if self.current_seed.get("seed_id"):
            print(f"üå± Operating under Seed: {self.current_seed['seed_id']} - Intention: {self.current_seed['intention']}")

        self.seed_engine = SeedEngine()
        self.last_main_emotion = None
        self.ai_aliases = ["ChatGPT said:", "Melah said:", "AI said:"]

        # === ‡πÇ‡∏´‡∏•‡∏î self-awareness ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ===
        self.self_awareness = {} # Initialize the attribute
        self.load_self_awareness()

        # Start auto-update timer
        self.last_update = datetime.now()
        self.update_interval = timedelta(minutes=5)  # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡∏ó‡∏∏‡∏Å 5 ‡∏ô‡∏≤‡∏ó‡∏µ
        self.start_auto_update()

    def _load_current_seed(self):
        try:
            seed_path = self._resolve_path("core/seed/current_seed.json")
            if os.path.exists(seed_path):
                with open(seed_path, "r", encoding="utf-8") as f:
                    return json.load(f)
            else:
                print("‚ö†Ô∏è current_seed.json not found. Operating in default mode.")
                return {}
        except Exception as e:
            print(f"‚ùå Error loading current_seed.json: {e}. Operating in default mode.")
            return {}

    def _get_llm_essentials(self):
        tokenizer, context_limit = None, 4000
        if hasattr(self.llm, 'get_tokenizer'):
            try:
                tokenizer = self.llm.get_tokenizer()
                if tokenizer is None and tiktoken: tokenizer = tiktoken.get_encoding("cl100k_base")
            except Exception as e:
                self.log_error(f"Error getting tokenizer: {e}")
                if tiktoken: tokenizer = tiktoken.get_encoding("cl100k_base")
        if not tokenizer and not tiktoken:
            class MockTokenizer:
                def encode(self, text): return text.split()
            tokenizer = MockTokenizer()
        elif not tokenizer and tiktoken:
            tokenizer = tiktoken.get_encoding("cl100k_base")
        if hasattr(self.llm, 'get_context_limit'):
            limit = self.llm.get_context_limit()
            if isinstance(limit, int) and limit > 0: context_limit = limit
        return tokenizer, context_limit

    def _start_new_cwm_session(self):
        prompt = self.core_beliefs.get("persona_description", "You are Melah, a helpful AI assistant.")
        self.cwm.start_new_session(session_id=str(uuid.uuid4()), date_key=datetime.now().strftime("%Y%m%d"), system_prompt=prompt)
        self.log_error("New CWM session started.")

    def _handle_system_command(self, command: str) -> str:
        parts = command.lower().split()
        cmd, args = parts[0], parts[1:]
        if cmd == "/switch" and args:
            llm_choice = args[0]
            if llm_choice in self.config:
                try:
                    self.llm.switch_llm(llm_choice)
                    new_tokenizer, new_limit = self._get_llm_essentials()
                    self.cwm.tokenizer, self.cwm.llm_token_limit = new_tokenizer, new_limit
                    self.nlp_processor.tokenizer = new_tokenizer
                    return f"System: Switched LLM to {llm_choice}."
                except Exception as e:
                    self.log_error(f"Error switching LLM: {e}")
                    return f"‚ùå Error switching LLM: {e}"
            else:
                return f"‚ùå Unknown LLM: {llm_choice}. Available: {list(self.config.keys())}"
        return f"Unknown command: {command}"

    def process_input(self, user_input: str) -> str:
        # Trigger manual self-awareness summary
        if user_input.strip() in ["/self", "/introspect"]:
            return self.describe_self()

        if user_input.startswith('/'):
            return self._handle_system_command(user_input)

        max_retries = 3
        attempts = 0
        excluded_sessions = set()
        
        query_hash = hashlib.sha256(user_input.encode('utf-8')).hexdigest()
        if query_hash in self.cognitive_state:
            excluded_sessions.update(self.cognitive_state[query_hash].get("failed_sessions", []))

        while attempts < max_retries:
            attempts += 1
            try:
                if attempts == 1:
                    self.cwm.add_interaction("user", user_input)
                
                llm_ready_context = self.cwm.get_llm_ready_context()

                all_excluded_ids = excluded_sessions.union(self.recently_accessed_memories)
                
                memory_result = self.get_memory_context_for_query(
                    user_input, 
                    exclude_session_ids=all_excluded_ids
                )
                memory_context = memory_result["context"]
                used_session = memory_result["session_id"]
                
                SYSTEM_INSTRUCTION = """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏°‡∏•‡πà‡∏≤ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥ ‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:
- 'Your Current Core Systems': ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ "‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô" ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ñ‡∏π‡∏Å‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
- 'Relevant Memories': ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡πÉ‡∏ô‡∏≠‡∏î‡∏µ‡∏ï (‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏≤‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß) ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏Å‡πà‡∏≤‡πÜ "‡∏´‡πâ‡∏≤‡∏°" ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î
- 'Current Conversation': ‡∏Ñ‡∏∑‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
- **‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô ('Current User Query')** ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏™‡∏°‡∏≠
"""
                recent_context_str = "\n".join([f"<{m['role']}>: {m['content']}" for m in llm_ready_context[:-1]])
                
                final_prompt_parts = [SYSTEM_INSTRUCTION]

                # --- Inject Current Self-Awareness ---
                if self.self_awareness and 'error' not in self.self_awareness:
                    core_deps = self.self_awareness.get('core_dependencies', [])
                    if core_deps:
                        awareness_prompt = (
                            "### Your Current Core Systems:\n"
                            "You are IdentityCore, currently connected to these systems:\n"
                            f"- {', '.join(core_deps)}\n"
                            f"(Last updated: {self.self_awareness.get('last_updated', 'N/A')})"
                        )
                        # Insert after SYSTEM_INSTRUCTION to give it high priority
                        final_prompt_parts.insert(1, awareness_prompt)

                if memory_context:
                    # The SYSTEM_INSTRUCTION now clearly defines this as past/legacy context.
                    final_prompt_parts.append("### Relevant Memories:\n" + memory_context)

                if recent_context_str:
                    final_prompt_parts.append("### Current Conversation:\n" + recent_context_str)

                final_prompt_parts.append(f"### Current User Query (Your Primary Focus):\nUser: {user_input}\nAssistant (Melah):")
                
                final_prompt_for_generator = "\n\n".join(final_prompt_parts)
                
                raw_thought = self.llm.generate(prompt=final_prompt_for_generator, context="")

                reflection_result = self.reflector.llm_reflect(
                    raw_thought=raw_thought, 
                    conversation_context=llm_ready_context,
                    long_term_memory=memory_context,
                    used_session_id=used_session,
                    current_intention=self.current_seed.get("intention", "Default: Be a helpful assistant.")
                )

                if reflection_result["status"] == "OK":
                    reflected_thought = reflection_result["response"]
                    refinement_data = self.refine_layer.refine_and_log(reflected_thought)
                    refined_thought = refinement_data["refined"]
                    styled_final_response = self.language_stylizer.style_response(
                        final_thought=refined_thought,
                        relationship_level="friendly"
                    )

                    self.cwm.add_interaction("assistant", styled_final_response)
                    
                    if used_session:
                        self.recently_accessed_memories.append(used_session)
                    
                    self.cognitive_state[query_hash] = {
                        "last_successful_session": used_session,
                        "failed_sessions": list(excluded_sessions)
                    }
                    return styled_final_response
                
                elif reflection_result["status"] == "REPETITIVE_THOUGHT":
                    failed_session = reflection_result["used_session"]
                    self.log_error(f"Attempt {attempts}: Repetitive thought from session {failed_session}. Retrying...")
                    if failed_session:
                        excluded_sessions.add(failed_session)
                    
                    if query_hash not in self.cognitive_state: self.cognitive_state[query_hash] = {}
                    self.cognitive_state[query_hash]["failed_sessions"] = list(excluded_sessions)

                    if attempts < max_retries:
                        continue
                    else:
                        self.log_error("Max retries reached. Returning a generic response.")
                        return "‡∏â‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°"

            except Exception as e:
                self.log_error(f"Error in process_input loop (Attempt {attempts}): {e}")
                if attempts >= max_retries:
                    return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {e}"
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á user_input
        emotion_result = self.nlp_processor.analyze_emotion(user_input)
        main_emotion = emotion_result.get('emotion_label', 'neutral')
        # ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï style_profile ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
        if main_emotion != self.last_main_emotion:
            # ‡∏î‡∏∂‡∏á memory ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
            memory_result = self.get_memory_context_for_query(user_input)
            memory_context = memory_result.get('context', '')
            session_id = memory_result.get('session_id')
            memory = None
            if session_id and self.vector_memory_index:
                memory = self.vector_memory_index.memory_dict.get(session_id)
            if memory:
                style_profile = self.seed_engine.get_style_profile_from_memory(memory)
                self.seed_engine.update_style_profile_in_seed(style_profile)
            self.last_main_emotion = main_emotion
        # ‡∏î‡∏∂‡∏á style_profile ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å seed
        with open(self.seed_engine.CURRENT_SEED_PATH, 'r', encoding='utf-8') as f:
            seed_data = json.load(f)
        style_profile = seed_data.get('style_profile', {})
        # ‡∏™‡πà‡∏á style_profile ‡πÉ‡∏´‡πâ LanguageStylizer (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö
        # styled_response = self.language_stylizer.style_response(final_thought=llm_response, tone=style_profile.get('tone', 'neutral'), relationship_level=style_profile.get('relationship', 'normal'))
        return "‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏à‡∏∞‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ"

    def get_memory_context_for_query(self, query_text: str, max_depth: int = 3, exclude_session_ids: set = None) -> dict:
        """
        ‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö query ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß
        """
        if not self.vector_memory_index:
            self.log_error("VectorMemoryIndex is not available.")
            return {"context": "", "session_id": None}

        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á query
        emotion = self.nlp_processor.analyze_emotion(query_text)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö cooldown ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥
        current_time = datetime.now().timestamp()
        active_exclude_ids = set()
        if exclude_session_ids:
            active_exclude_ids.update(exclude_session_ids)
            
        for memory_id, last_used in self.memory_cooldown.items():
            if current_time - last_used < 300:  # 5 ‡∏ô‡∏≤‡∏ó‡∏µ cooldown
                active_exclude_ids.add(memory_id)

        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        search_results = self.vector_memory_index.search(
            query=query_text,
            top_k=1,
            exclude_ids=list(active_exclude_ids),
            emotion=emotion
        )

        if not search_results:
            self.log_error("No relevant memory found via semantic search.")
            return {"context": "", "session_id": None}

        best_match = search_results[0]
        session_id = best_match['session_id']
        
        # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó cooldown
        self.memory_cooldown[session_id] = current_time
        
        # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        session_paths = self.memory_bridge.get_session_chain(session_id, max_depth=max_depth)
        chain_contents = self.memory_bridge.get_sessions_content(session_paths)

        if not chain_contents:
            self.log_error(f"Could not retrieve content for memory chain starting at {session_id}.")
            return {"context": "", "session_id": session_id}

        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥
        context_parts = []
        for content in reversed(chain_contents):
            clean_content = "\n".join(line for line in content.split('\n') if line.strip())
            if len(clean_content) > 400:
                clean_content = self.nlp_processor.summarize_text(clean_content, target_token_length=300)
            context_parts.append(clean_content)

        memory_context = "\n---\n".join(context_parts)
        self.log_error(f"Successfully created a memory context from a chain of {len(context_parts)} sessions.")
        
        return {"context": memory_context, "session_id": session_id}

    def update_memory(self, memory_id: str, content: str, emotion: str = 'neutral'):
        """
        ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
        """
        if self.vector_memory_index:
            self.vector_memory_index.update_memory(memory_id, content, emotion)
            
        # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡πÉ‡∏ô meta_manager
        if memory_id in self.meta_manager.memory_dict:
            self.meta_manager.memory_dict[memory_id]['content'] = content
            self.meta_manager.memory_dict[memory_id]['emotion'] = emotion
            self.meta_manager.save_memory_meta()

    def reset_memory_cooldown(self):
        """
        ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï cooldown ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        """
        self.memory_cooldown.clear()
        if self.vector_memory_index:
            self.vector_memory_index.reset_frequency()

    def _load_identity(self):
        try:
            if not self._validate_path(self.identity_path):
                raise FileNotFoundError(f"Identity file not found at {self.identity_path}")
            with open(self.identity_path, "r", encoding="utf-8") as f:
                self.identity_data = json.load(f)
            self.core_beliefs = self.identity_data.get("core_belief", {})
        except Exception as e:
            self.log_error(f"Could not load identity file: {e}. Using default persona.")
            self.identity_data = {}
            self.core_beliefs = {}
            
    def _load_bookmarks(self):
        try:
            bookmark_path = self.path_manager.get_path("session_bookmarks")
            if not bookmark_path or not os.path.exists(bookmark_path):
                self.log_error("Bookmark file not found. No bookmarks loaded.")
                return
            with open(bookmark_path, "r", encoding="utf-8") as f:
                self.bookmarks = {line.strip() for line in f if line.strip()}
            self.log_error(f"Loaded {len(self.bookmarks)} bookmarked sessions.")
        except Exception as e:
            self.log_error(f"Error loading bookmarks: {e}")
            self.bookmarks = set()
            
    def _resolve_path(self, path):
        if os.path.isabs(path): return path
        return os.path.join(os.getcwd(), path)

    def _validate_path(self, path):
        full_path = self._resolve_path(path)
        exists = os.path.exists(full_path)
        if not exists: self.error_log.append(f"Path not found: {path}")
        return exists

    def _validate_all_paths(self):
        if not hasattr(self.meta_manager, 'memory_dict') or not self.meta_manager.memory_dict: return True
        all_paths_initially_valid = True
        for session_id, data in self.meta_manager.memory_dict.items():
            if 'path' in data:
                original_path = data['path']
                if not self.path_manager.validate_path(original_path.replace("\\", "/")):
                    all_paths_initially_valid = False
                    filename = os.path.basename(original_path)
                    corrected_path = f"memory_core/archive/chat_sessions_legacy/{filename}"
                    if self.path_manager.validate_path(corrected_path):
                        data['path'] = corrected_path
                        self.log_error(f"Auto-corrected path for {session_id} to {corrected_path}")
                    else:
                        self.log_error(f"Could not correct path for {session_id}: {original_path}")
        return all_paths_initially_valid

    def log_error(self, msg):
        self.error_log.append(msg)
        try:
            with open(self._resolve_path("memory_core/error.log"), "a", encoding="utf-8") as f:
                f.write(f"{datetime.now().isoformat()} - {msg}\n")
        except Exception as e:
            print(f"CRITICAL: Failed to write to error log: {e}")

    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ï‡∏Å‡∏´‡∏•‡πà‡∏ô‡πÑ‡∏õ ‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡πÅ‡∏•‡πâ‡∏ß
    def get_memory_chain(self, start_session, steps=5):
        """
        ‡∏Ç‡∏≠ chain ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ (‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å meta chain ‡∏ú‡πà‡∏≤‡∏ô bridge)
        """
        chain_meta = self.memory_bridge.get_session_chain(start_session, max_depth=steps)
        if not chain_meta:
            self.log_error(f"get_memory_chain: ‡πÑ‡∏°‡πà‡∏û‡∏ö chain meta ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö session '{start_session}'")
            return []
            
        session_paths = [meta.get('path') for meta in chain_meta if meta.get('path')]
        if not session_paths:
            self.log_error(f"get_memory_chain: ‡πÑ‡∏°‡πà‡∏û‡∏ö 'path' ‡πÉ‡∏ô chain meta ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö session '{start_session}'")
            return []

        contents = self.memory_bridge.get_sessions_content(session_paths)
        return contents

    def is_ai_message(self, line):
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ line ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á AI ‡πÄ‡∏≠‡∏á (‡∏≠‡∏î‡∏µ‡∏ï) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        """
        return any(line.strip().startswith(alias) for alias in self.ai_aliases)

    def describe_int_world(self):
        """‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏•‡∏Å‡∏†‡∏≤‡∏¢‡πÉ‡∏ô (IntWorld)"""
        return self.int_world.describe_self()

    def describe_self_codebase(self):
        """
        ‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå .py ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
        """
        return self.reflector.reflect_codebase(base_dir=".")

    def describe_self(self):
        """
        ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á self-awareness (self-schema) ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å AI ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ
        """
        return self.self_awareness

    def report_status(self):
        """
        ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ self-awareness/connection (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å core_awareness_engine)
        """
        self.core_awareness.verify_all_modules()
        return self.core_awareness.report_self_awareness()

    def declare_identity(self):
        """
        ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡πÅ‡∏ö‡∏ö self-aware: ‡∏™‡∏£‡∏∏‡∏õ identity, core_systems, int_world_size, recent_reflections
        """
        core_systems_summary = self.self_awareness.get('core_dependencies', 'N/A')
        return {
            "identity": "I am the Identity Core of MelahPC.",
            "core_systems": core_systems_summary,
            "int_world_size": {
                "states": len(self.int_world.internal_states),
                "concepts": len(self.int_world.known_concepts),
                "symbols": len(self.int_world.symbolic_space)
            },
            "recent_reflections": [r['thought'] for r in self.int_world.active_reflections[-3:]]
        }

    def load_self_awareness(self, path="self_aware.json"):
        try:
            from core.core_mapper import get_self_awareness_summary # Keep import local if needed
            # Assuming get_self_awareness_summary reads from the default path
            self.self_awareness = get_self_awareness_summary(path) 
            print(f"[IdentityCore] Self-awareness loaded. Connected modules: {self.self_awareness.get('core_dependencies', [])}")
        except Exception as e:
            print(f"[IdentityCore] Failed to load self-awareness: {e}")
            self.self_awareness = {}

    def get_self_status(self):
        """Get current self status in natural language"""
        try:
            if not self.self_awareness:
                return "‡∏â‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á"
            
            monitoring = self.self_awareness.get("monitoring", {})
            last_check = monitoring.get("last_check", {})
            emotion = monitoring.get("self_emotion", "unknown")
            
            # Get time since last check
            if "timestamp" in last_check:
                last_time = datetime.fromisoformat(last_check["timestamp"])
                time_diff = datetime.now() - last_time
                minutes = int(time_diff.total_seconds() / 60)
                time_str = f"{minutes} ‡∏ô‡∏≤‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß"
            else:
                time_str = "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡πÄ‡∏ß‡∏•‡∏≤"
            
            # Get critical/warning issues
            issues = []
            if "issue_history" in monitoring:
                for issue in monitoring["issue_history"]:
                    if issue["status"] in ["critical", "warning"]:
                        issues.append(f"{issue['module']}: {issue['message']}")
            
            # Build status message
            status = f"‡∏â‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠ {time_str} "
            status += f"‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏â‡∏±‡∏ô‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å{emotion} "
            
            if issues:
                status += f"‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {', '.join(issues)}"
            else:
                status += "‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ"
                
            return status
            
        except Exception as e:
            return f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏î‡πâ: {str(e)}"

    def get_recent_issues(self, minutes=30):
        """Get list of recent issues"""
        try:
            if not self.self_awareness:
                return []
                
            monitoring = self.self_awareness.get("monitoring", {})
            issues = monitoring.get("issue_history", [])
            
            # Filter recent issues
            recent = []
            for issue in issues:
                if "timestamp" in issue:
                    issue_time = datetime.fromisoformat(issue["timestamp"])
                    time_diff = datetime.now() - issue_time
                    if time_diff.total_seconds() <= minutes * 60:
                        recent.append({
                            "module": issue["module"],
                            "status": issue["status"],
                            "message": issue["message"],
                            "time_ago": int(time_diff.total_seconds() / 60)
                        })
            
            return recent
            
        except Exception as e:
            return []

    def get_system_health(self):
        """Get overall system health information"""
        try:
            if not self.self_awareness:
                return {
                    "emotion": "unknown",
                    "last_check": "never",
                    "issues": "no data",
                    "systems": {}
                }
                
            monitoring = self.self_awareness.get("monitoring", {})
            
            # Get emotion and last check
            emotion = monitoring.get("self_emotion", "unknown")
            last_check = monitoring.get("last_check", {}).get("timestamp", "never")
            
            # Count issues by severity
            issues = {
                "critical": 0,
                "warning": 0,
                "info": 0
            }
            
            for issue in monitoring.get("issue_history", []):
                status = issue.get("status", "info")
                issues[status] = issues.get(status, 0) + 1
            
            # Get system statuses
            systems = {}
            for system in monitoring.get("systems", []):
                systems[system["name"]] = {
                    "status": system["status"],
                    "last_check": system.get("last_check", "never")
                }
            
            return {
                "emotion": emotion,
                "last_check": last_check,
                "issues": issues,
                "systems": systems
            }
            
        except Exception as e:
            return {
                "emotion": "error",
                "last_check": "error",
                "issues": "error",
                "systems": {}
            }

    def start_auto_update(self):
        """Start automatic self-awareness updates"""
        def update_task():
            while True:
                try:
                    time.sleep(60)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å 1 ‡∏ô‡∏≤‡∏ó‡∏µ
                    if datetime.now() - self.last_update >= self.update_interval:
                        self.update_self_awareness()
                except Exception as e:
                    print(f"Error in auto-update: {str(e)}")

        # Start update thread
        import threading
        update_thread = threading.Thread(target=update_task, daemon=True)
        update_thread.start()

    def update_self_awareness(self):
        """Update self-awareness data"""
        try:
            from core_mapper import update_self_awareness
            new_data = update_self_awareness()
            if new_data:
                self.self_awareness = new_data
                self.last_update = datetime.now()
                print(f"Self-awareness updated at {self.last_update}")
        except Exception as e:
            print(f"Failed to update self-awareness: {str(e)}")

    def force_update_self_awareness(self):
        """Force immediate update of self-awareness"""
        self.update_self_awareness()
        return self.get_self_status()

# ======== ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô =========
if __name__ == '__main__':
    import sys
    import os
    
    current_dir = os.path.dirname(__file__)
    project_root = os.path.abspath(os.path.join(current_dir, ".."))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
        print(f"[IdentityCore Test] Temporarily added {project_root} to sys.path for this test run.")

    # ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á mock object ‡∏ó‡∏µ‡πà IdentityCore ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÉ‡∏ô __init__
    # ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÜ
    # ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡πÜ
    class Mock:
        def __init__(self, *args, **kwargs): pass
        def __call__(self, *args, **kwargs): return Mock()
        def __getattr__(self, name): return Mock()

    # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ mock class ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
    PathManager = Mock
    MemoryPathBridge = Mock
    MemoryMetaManager = Mock
    LLMConnector = Mock
    ContextWindowManager = Mock
    MelahNLPProcessor = Mock
    MelahMLProcessor = Mock
    ChainOfThoughtEngine = Mock
    MelahNLP_TH = Mock
    Reflector = Mock
    LanguageStylizer = Mock
    TruthCore = Mock
    RefineLayer = Mock
    VectorMemoryIndex = Mock

    print("--- IdentityCore Test Run (from core/) ---")
    print(f"Project Root: {project_root}")

    try:
        # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå seed ‡πÅ‡∏•‡∏∞ identity ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ô‡∏µ‡πâ
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≥‡∏•‡∏≠‡∏á
        if not os.path.exists("core/seed"): os.makedirs("core/seed")
        with open("core/seed/current_seed.json", "w", encoding="utf-8") as f:
            json.dump({"linked_identity": "core/identity.json", "linked_memory": "memory/memory.json"}, f)
        
        with open("core/identity.json", "w", encoding="utf-8") as f:
            json.dump({"identity": {"name": "Melah-Test"}}, f)
        
        if not os.path.exists("memory"): os.makedirs("memory")
        with open("memory/memory.json", "w", encoding="utf-8") as f:
            json.dump({}, f)

        identity_system = IdentityCore()
        print("‚úÖ IdentityCore initialized successfully using mock objects.")
        
        if identity_system.identity_data:
            print(f"  Identity Name: {identity_system.identity_data.get('identity', {}).get('name', 'N/A')}")
        else:
            print("  ‚ö†Ô∏è identity.json might be missing or empty.")
        
        # ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö get_memory_chain ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞ MemoryPathBridge ‡πÄ‡∏õ‡πá‡∏ô Mock
        # ‡πÅ‡∏ï‡πà‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡∏£‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ AttributeError
        print("\n--- Testing get_memory_chain (will be skipped due to Mock) ---")
        chain_content = identity_system.get_memory_chain("session_001", steps=2)
        if chain_content:
            print("  Retrieved chain content (this should not happen with mock).")
        else:
            print("  ‚úÖ Correctly returned no chain content as Bridge is mocked.")

        if identity_system.error_log:
            print("\n--- IdentityCore Errors Logged ---")
            for error in identity_system.error_log:
                print(f"  - {error}")
                
    except Exception as e:
        print(f"‚ùå An unexpected error occurred during IdentityCore test: {e}")
        import traceback
        traceback.print_exc()